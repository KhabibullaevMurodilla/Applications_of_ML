{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4c3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to load our datasets and see how they are look like\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#we are using .dat file which is seperated by tab\n",
    "#so we use '\\t' as delimiter\n",
    "user_data = pd.read_csv('/Users/user/Downloads/hetrec2011-lastfm-2k/user_artists.dat', delimiter='\\t')\n",
    "product_data = pd.read_csv('/Users/user/Downloads/hetrec2011-lastfm-2k/artists.dat', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ed8bb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>13883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>11690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>11351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>8983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  artistID  weight\n",
       "0       2        51   13883\n",
       "1       2        52   11690\n",
       "2       2        53   11351\n",
       "3       2        54   10300\n",
       "4       2        55    8983"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's have a look our datasets to understand\n",
    "#structure of data\n",
    "\n",
    "user_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb77f25",
   "metadata": {},
   "source": [
    "So, we have *userID*, *artistID* which identifies artist and *weight* which defines the count of the artist listened by user. Maybe we need something different like *rating* instead of *weight*. We will decide later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a456fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92834 entries, 0 to 92833\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   userID    92834 non-null  int64\n",
      " 1   artistID  92834 non-null  int64\n",
      " 2   weight    92834 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "#let's get some information about the dataframe\n",
    "user_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44137a6f",
   "metadata": {},
   "source": [
    "It looks clean, no missing values i think."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f538ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>pictureURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MALICE MIZER</td>\n",
       "      <td>http://www.last.fm/music/MALICE+MIZER</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/10808.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Diary of Dreams</td>\n",
       "      <td>http://www.last.fm/music/Diary+of+Dreams</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/3052066.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Carpathian Forest</td>\n",
       "      <td>http://www.last.fm/music/Carpathian+Forest</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/40222717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Moi dix Mois</td>\n",
       "      <td>http://www.last.fm/music/Moi+dix+Mois</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/54697835...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bella Morte</td>\n",
       "      <td>http://www.last.fm/music/Bella+Morte</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/14789013...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               name                                         url  \\\n",
       "0   1       MALICE MIZER       http://www.last.fm/music/MALICE+MIZER   \n",
       "1   2    Diary of Dreams    http://www.last.fm/music/Diary+of+Dreams   \n",
       "2   3  Carpathian Forest  http://www.last.fm/music/Carpathian+Forest   \n",
       "3   4       Moi dix Mois       http://www.last.fm/music/Moi+dix+Mois   \n",
       "4   5        Bella Morte        http://www.last.fm/music/Bella+Morte   \n",
       "\n",
       "                                          pictureURL  \n",
       "0    http://userserve-ak.last.fm/serve/252/10808.jpg  \n",
       "1  http://userserve-ak.last.fm/serve/252/3052066.jpg  \n",
       "2  http://userserve-ak.last.fm/serve/252/40222717...  \n",
       "3  http://userserve-ak.last.fm/serve/252/54697835...  \n",
       "4  http://userserve-ak.last.fm/serve/252/14789013...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now it's turn to product_data\n",
    "product_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ad71ec",
   "metadata": {},
   "source": [
    "So, we have four columns. And I think the most important ones for our task are *id* and *name*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56887c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17632 entries, 0 to 17631\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   id          17632 non-null  int64 \n",
      " 1   name        17632 non-null  object\n",
      " 2   url         17632 non-null  object\n",
      " 3   pictureURL  17188 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 551.1+ KB\n"
     ]
    }
   ],
   "source": [
    "product_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2384af",
   "metadata": {},
   "source": [
    "No null values in important ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c09a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, I think it is time to next steps\n",
    "#Let's create a function to load data incase we need in the future\n",
    "def load_data(user_data_file, product_data_file):\n",
    "    \n",
    "    #we are using .dat file which is seperated by tab\n",
    "    #so we use '\\t' as delimiter\n",
    "    user_data = pd.read_csv(user_data_file, delimiter='\\t')\n",
    "    product_data = pd.read_csv(product_data_file, delimiter='\\t')\n",
    "    \n",
    "    # Here we create 'rating' column which might be more appropriate\n",
    "    user_data['rating'] = user_data['weight']*5/max(user_data['weight'])\n",
    "    \n",
    "    return user_data, product_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb6acdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9906\n",
      "MAE: 0.9901\n"
     ]
    }
   ],
   "source": [
    "#Let's try to create collaborative filtering and\n",
    "#test its performance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from surprise.dataset import Dataset, Reader\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "#Loading data\n",
    "user_data, product_data = load_data('/Users/user/Downloads/hetrec2011-lastfm-2k/user_artists.dat', '/Users/user/Downloads/hetrec2011-lastfm-2k/artists.dat')\n",
    "\n",
    "#Splitting data into train and test sets so that we can accuracy of predictions\n",
    "train_set, test_set = train_test_split(user_data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Collaborative filtering module\n",
    "def collaborative_filtering(train_data):\n",
    "    reader = Reader(rating_scale=(1, 5)) \n",
    "    data = Dataset.load_from_df(train_data[['userID', 'artistID', 'rating']], reader)\n",
    "    algo = SVD()\n",
    "    trainset = data.build_full_trainset()\n",
    "    algo.fit(trainset)\n",
    "    \n",
    "    return algo\n",
    "\n",
    "#Training the module\n",
    "collab_model = collaborative_filtering(train_set)\n",
    "\n",
    "#Testing and showing results\n",
    "predictions = []\n",
    "actual_ratings = []\n",
    "for _, row in test_set.iterrows():\n",
    "    user_id = row['userID']\n",
    "    item_id = row['artistID']\n",
    "    rating = row['rating']\n",
    "    pred = collab_model.predict(user_id, item_id)\n",
    "    predictions.append(pred.est)\n",
    "    actual_ratings.append(rating)\n",
    "rmse = mean_squared_error(actual_ratings, predictions, squared=False)\n",
    "mae = mean_absolute_error(actual_ratings, predictions)\n",
    "\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c8b901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "551/551 [==============================] - 69s 117ms/step - loss: 0.0277\n",
      "Epoch 2/10\n",
      "551/551 [==============================] - 62s 112ms/step - loss: 6.7711e-04\n",
      "Epoch 3/10\n",
      "551/551 [==============================] - 70s 126ms/step - loss: 6.8208e-04\n",
      "Epoch 4/10\n",
      "551/551 [==============================] - 76s 137ms/step - loss: 6.8507e-04\n",
      "Epoch 5/10\n",
      "551/551 [==============================] - 65s 117ms/step - loss: 6.8656e-04\n",
      "Epoch 6/10\n",
      "551/551 [==============================] - 63s 114ms/step - loss: 6.8881e-04\n",
      "Epoch 7/10\n",
      "551/551 [==============================] - 62s 112ms/step - loss: 6.8898e-04\n",
      "Epoch 8/10\n",
      "551/551 [==============================] - 64s 116ms/step - loss: 6.8700e-04\n",
      "Epoch 9/10\n",
      "551/551 [==============================] - 69s 126ms/step - loss: 6.8525e-04\n",
      "Epoch 10/10\n",
      "551/551 [==============================] - 72s 131ms/step - loss: 6.8189e-04\n",
      "551/551 [==============================] - 11s 19ms/step\n",
      "          id                             name  \\\n",
      "17631  18745                 Grzegorz Tomczak   \n",
      "5879    6004                       Mr. Scruff   \n",
      "5873    5998  Madonna feat. Justin Timberlake   \n",
      "5874    5999                           Zombie   \n",
      "5875    6000               LanzamientosMp3.es   \n",
      "...      ...                              ...   \n",
      "11748  12174                     Leo e Junior   \n",
      "11747  12173            Gustavo Moura & Rafae   \n",
      "11746  12172          César Menotti & Fabiano   \n",
      "11745  12171                  Rodrigo Del Arc   \n",
      "0          1                     MALICE MIZER   \n",
      "\n",
      "                                                     url  \\\n",
      "17631          http://www.last.fm/music/Grzegorz+Tomczak   \n",
      "5879                 http://www.last.fm/music/Mr.+Scruff   \n",
      "5873   http://www.last.fm/music/Madonna+feat.+Justin+...   \n",
      "5874                     http://www.last.fm/music/Zombie   \n",
      "5875         http://www.last.fm/music/LanzamientosMp3.es   \n",
      "...                                                  ...   \n",
      "11748              http://www.last.fm/music/Leo+e+Junior   \n",
      "11747  http://www.last.fm/music/Gustavo%2BMoura%2B%25...   \n",
      "11746  http://www.last.fm/music/C%25C3%25A9sar%2BMeno...   \n",
      "11745           http://www.last.fm/music/Rodrigo+Del+Arc   \n",
      "0                  http://www.last.fm/music/MALICE+MIZER   \n",
      "\n",
      "                                              pictureURL  \n",
      "17631  http://userserve-ak.last.fm/serve/252/59486303...  \n",
      "5879   http://userserve-ak.last.fm/serve/252/40947881...  \n",
      "5873   http://userserve-ak.last.fm/serve/252/30705889...  \n",
      "5874    http://userserve-ak.last.fm/serve/252/297390.jpg  \n",
      "5875   http://userserve-ak.last.fm/serve/252/24280293...  \n",
      "...                                                  ...  \n",
      "11748  http://userserve-ak.last.fm/serve/252/48425419...  \n",
      "11747                                                NaN  \n",
      "11746  http://userserve-ak.last.fm/serve/252/33974593...  \n",
      "11745  http://userserve-ak.last.fm/serve/252/20157875...  \n",
      "0        http://userserve-ak.last.fm/serve/252/10808.jpg  \n",
      "\n",
      "[17632 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/63/tn3fsjp55gb83_x7q74hppjw0000gn/T/ipykernel_1011/2162349917.py:47: RuntimeWarning: invalid value encountered in divide\n",
      "  content_predictions = content_model[user_liked_products_indices].sum(axis=0) / len(user_liked_products_indices)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Content-based filtering module with deep learning\n",
    "def content_based_filtering(product_data):\n",
    "    # Text preprocessing\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(product_data['name'])\n",
    "    sequences = tokenizer.texts_to_sequences(product_data['name'])\n",
    "    max_length = max([len(seq) for seq in sequences])\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "    \n",
    "    # Deep learning model for product representation\n",
    "    embedding_dim = 128\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(product_data.shape[0], activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    model.fit(padded_sequences, np.eye(product_data.shape[0]), epochs=10, batch_size=32)\n",
    "    \n",
    "    # Compute product similarity matrix\n",
    "    product_representations = model.predict(padded_sequences)\n",
    "    product_similarity_matrix = cosine_similarity(product_representations)\n",
    "    \n",
    "    return product_similarity_matrix\n",
    "\n",
    "# Hybrid recommendation system\n",
    "def hybrid_recommendation(user_id, user_data, product_data, collab_model, content_model, alpha=0.5):\n",
    "    user_interactions = user_data[user_data['userID'] == user_id]\n",
    "    \n",
    "    # Collaborative filtering predictions\n",
    "    collab_predictions = [collab_model.predict(user_id, product_id)[3] for product_id in product_data['id']]\n",
    "    \n",
    "    # Content-based filtering predictions\n",
    "    user_liked_products = user_interactions[user_interactions['rating'] > 3]['artistID']\n",
    "    user_liked_products_indices = [product_data[product_data['id'] == product_id].index[0] for product_id in user_liked_products]\n",
    "    content_predictions = content_model[user_liked_products_indices].sum(axis=0) / len(user_liked_products_indices)\n",
    "    \n",
    "    # Hybrid recommendations\n",
    "    hybrid_predictions = alpha * np.array(collab_predictions) + (1 - alpha) * np.array(content_predictions)\n",
    "    hybrid_recommendations = product_data.iloc[hybrid_predictions.argsort()[::-1]]\n",
    "    \n",
    "    return hybrid_recommendations\n",
    "\n",
    "# Example usage\n",
    "user_data, product_data = load_data('/Users/user/Downloads/hetrec2011-lastfm-2k/user_artists.dat', '/Users/user/Downloads/hetrec2011-lastfm-2k/artists.dat')\n",
    "collab_model = collaborative_filtering(user_data)\n",
    "content_model = content_based_filtering(product_data)\n",
    "\n",
    "user_id = 123  # Example user ID\n",
    "hybrid_recommendations = hybrid_recommendation(user_id, user_data, product_data, collab_model, content_model)\n",
    "print(hybrid_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef67433f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
